# Face X-ray for More General Face Forgery Detection

## 创新点

- 提出了一种名为Face X-ray的人脸伪造检测方法，该方法不仅能够检测伪造方法还能定位相应的伪造区域；该方法具备极其良好的泛化性能，并且能够在只有真实人脸图片的条件下进行训练。

## 主要内容

<img src="file:///home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_001.png" title="" alt="" data-align="center">

**概述**：

典型的人脸伪造方法主要包括以下三个阶段：

1. 检测待伪造的面部区域

2. 生成伪造的目标面部区域 

3. 将源图片和目标人脸进行融合

当前的人脸伪造方法主要集中于通过检测第二阶段中产生出伪造伪影来检测真伪。一个客观事实是对于每一张图片而言其都会存在一个独一无二特征标志，这样的一个特征标志往往是由硬件和软件两个部分共同造成的。作者认为第三阶段的融合过程会产生一个融合的边界，在边界的两侧会存在不一致图片特征，因此可以利用这种不一致来检测融合边界进而实现的对人脸伪造的检测。

### Face X-ray

![](/home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_002.png)

#### 伪造图片生成

$$
I_M=M \cdot I_F+(1-M) \cdot I_B

$$

对于一张伪造图片$I_M$而言，其可以简化地表示成由前景图片(包含目标人脸区域的图片)$I_F$和背景图片$I_B$融合而成，$M$则是用来对二者进行融合操作的掩码，掩码区域$M$往往是一张灰度图片，值往往属于0-1之间，根据融合的方式不同其会存在着一定的差别，在Poisson blending泊松融合中掩码区域$M$就是二值化的灰度图。需要注意的是在进行融合操作之前往往需要对前景图片$I_F$进行颜色矫正来使得前景图片$I_F$的颜色与背景图片$I_B$保持一致。

#### Face X-ray

<img src="file:///home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_003.png" title="" alt="" data-align="center">

这里将图片的Face X-ray定义为图片$B$，其中每个像素的值如下:

$$
B_{i,j}=4*M_{i,j}*(1-M_{i,j})
$$

$M$是从输入的图片中提取的掩码，对于真实输入图片而言，掩码区域$M$的值为全0或者全1，而对于伪造图片而言，提取出的掩码区域$M$则标识出属于前景图片的部分，如图中的final_mask。

**需要注意的是，这里的掩码区域$M$与融合过程中的使用掩码区域在取值存在着一定的区别，在融合过程中的掩码区域的选值可以为二值的，如前文提及的泊松分布中的融合掩码，但是在Face X-ray的定义中掩码区域$M$的取值是不可以二值化的，因为二值化会导致生成的Face X-ray图像B为空白图像，进而导致无法实现检测伪造区域边界的目的，因此在上图生成最后的掩码区域final mask时需要进行一步模糊操作，其会使用一个3*3的高斯核来对图片进行模糊操作，将二者化的掩码区域转换成非二值化的掩码区域。**

考虑到$M_{i,j}*(1-M_{i,j})$的最大值为0.25，因此需要在式中乘4来将值映射到一个0-1的区间中。

### Face X-ray的获取

**一般方法：**

作者定义这样一个称为Face X-ray的计算量的目的是为模型提供一个监督来指示模型去发现输入人脸的图片中存在差异，这种差异是由于融合边界的两侧的图片区域的来源不同。因此作者后面根据这样的定义来生成相应融合图片以及对应的作为标签的Face X-ray来对模型进行训练。

在定义了Face X-ray后，我们想要获取相应的包含Face X-ray的标签的训练数据可能会考虑如下两种方式：

- 直接使用现有的伪造数据集，将伪造人脸图片和真实人脸图片之间取差异值来获取相应的掩码区域$M$来计算相应的Face X-ray

- 自行使用伪造方法去生成伪造图片并产生相应的Face X-ray标签来作为训练数据

**作者的方法：**

但是作者提出了使用真实图片来进行一个简单图片融合的方法来自动化地产生相应的训练数据，如前文所述对于Face X-ray而言真正重要的不是如何去对面部进行伪造操作，而是图片融合操作中所产生出边界。

具体生成训练数据的步骤如下：

1. 首先输入一个真实人脸视频，从其中定位出人脸图片作为背景图片$I_B$，然后使用人脸地标点的欧式距离为标准去训练数据中如下的真实人脸视频中找到最接近的100个人脸，然后从这100个最接近的人脸中选择出一个人脸图片来作为前景图片$I_F$。

2. 从背景图片$I_B$的人脸中生成掩码区域$M$：
   
   - 首先从背景图片的人脸中随机选择一个4*4的网格区域，进而获得16个原始点
   
   - 对这16个点进行随机的仿射变换获取新的16个点
   
   - 以新的16个点来构建凸包来生成初始的掩码区域，这时候得到掩码去往往是二值化的。
   
   - 对初始的掩码区域进行高斯模糊来获取非二值化的掩码区域作为最终的掩码区域

3. 在融合前对目标图片区域进行颜色矫正，将前景图像的RGB三通道的每个通道的均值与后景图像进行对齐。

4. 根据前文所述定义来生成相应的融合后图片和相应的Face X-ray来作为标签。

**优点**：

1. 作者的方法能够动态地随机地生成多样化的融合边界，同时由于其简化的操作不会引入多余信息来误导网络，因此其生成数据可以使得网络专注于去寻找融合边界。

2. 相较于使用现有伪造数据来产生伪造数据的方法而言，其能够产生更加多样化的融合边界，避免模型在特定伪造数据上发生过拟合，导致在面对未知伪造数据时泛化性变差。

3. 对于第二种方法而言，作者使用方法能够避免模型像之前大多数方法一样过于关注于伪造过程中的第二阶段而不是融合操作，虽然可以在后续网络使用损失函数来缓解，但是多少会对背离初衷，存在着泛化性变差的风险，同时同上面第二点，其也存在产生的融合边界不够多样化的风险，虽然可以通过增加伪造方法的种类来在一定程度上缓解，但是这样会大大增加工作量。

### 总体网络设计

作者首先使用HRnet网络去预测融合边界$B^-$，然后再在$B^-$上使用全局池化和全连接层来预测最终真伪结果，作者使用$L=aL_b+L_c$来作为损失函数，其中$L_c$是二分类损失，用来计算真伪的预测损失，而$L_b$则是用来评估融合边界的预测损失：

<img src="file:///home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_004.png" title="" alt="./img/face X-ray/选区_004.png" data-align="center">

其主要计算对应位置上差异来比较预测的融合边界的精确度，实验过程a=100来强迫网络去学习预测Face X-ray。

## 实验结果

<img src="file:///home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_005.png" title="" alt="" data-align="center">

不同的网络在使用相同训练集进行训练的情况下泛化性情况，可以看到作者提出的Face X-ray方法具备了最佳的泛化性能。需要说明的是在使用Face X-ray时，对于FF++这类伪造数据集时，使用真实图片来作为背景图片，使用伪造图片来作为前景图片，以此生成训练数据。**表中的BI数据集是作者只使用真实图片来进行融合操作生成的数据集**，我们可以看到在同时使用该数据集来训练的情况下，不同方法都取得很高的泛化性，这可能是因为训练数据导致三种方法的都趋向于对融合边界这个特征进行识别，即Xception和HRnet和Face X-ray学习到了类似的特征模式。

![](/home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_006.png)

使用FF++和BI作为训练集，在当前主流的其他数据上的训练结果，Face X-ray方法依旧表现出了优异的泛化性能。

<img src="file:///home/zwplus/文档/blog/paper-blog/img/face%20X-ray/选区_007.png" title="" alt="" data-align="center">

表4中作者比较了一下掩码区域的随机变形（仿射变换）和颜色矫正对于方法性能的影响；表5比较了使用损失函数中使用不同的a对于最终结果的影响；表6则比较了在融合过程使用不同融合方式生成相应的训练数据对模型性能的影响。

## 存在固有缺陷

1. 本文提出的方法是基于在生成伪造图片的过程存在融合操作这样一个过程，但是对于使用GAN这一类完全生成的伪造图片，基本无法进行检测

2. 可以通过生成对抗样本来针对本文检测方法来进行攻击，来逃避检测。

3. 本文的方法与当前的其他伪造检测器类似，在面对着低分辨率的视频时的检测性能会出现明显下降。
